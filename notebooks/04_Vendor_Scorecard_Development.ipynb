{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vendor Scorecard Development\n",
    "\n",
    "This notebook implements the FinTech Vendor Scorecard for Micro-Lending.\n",
    "It combines entities extracted by the NER model with Telegram post metadata\n",
    "(views, timestamps, channel/vendor name) to create a rich profile for each vendor.\n",
    "It then calculates key performance metrics and a weighted \"Lending Score\" for each.\n",
    "\n",
    "This notebook is a core component of the FinTech E-commerce Data Extractor project,\n",
    "specifically designed to fulfill the business objective of identifying promising\n",
    "vendors for micro-lending opportunities within the EthioMart ecosystem.\n",
    "\n",
    "**Project Goal:** To leverage unstructured Telegram e-commerce data to provide\n",
    "data-driven insights for financial decision-making, particularly micro-lending.\n",
    "\n",
    "**Business Objective:** Enable EthioMart to make informed micro-lending decisions\n",
    "by quantifying vendor performance and potential based on their digital footprint\n",
    "and engagement on Telegram channels. This aims to reduce risk and optimize lending\n",
    "to active and successful small businesses.\n",
    "\n",
    "**Methodology:**\n",
    "The methodology integrates several stages of data processing and analysis:\n",
    "1.  **Data Integration:** Utilizes preprocessed Telegram message data, incorporating\n",
    "    critical metadata such as message views, posting dates, and channel information.\n",
    "2.  **Entity Extraction:** Employs a fine-tuned Named Entity Recognition (NER) model\n",
    "    to accurately extract crucial business entities (Product, Price, Location, Contact Info)\n",
    "    from the free-form Amharic text of Telegram posts.\n",
    "3.  **Vendor Analytics Engine Development:** Constructs a robust analytics engine\n",
    "    to compute key performance indicators for each vendor, transforming raw data\n",
    "    and extracted entities into quantifiable metrics.\n",
    "4.  **Lending Score Formulation:** Develops a composite \"Lending Score\" by normalizing\n",
    "    and weighting selected performance indicators, providing a single, interpretable\n",
    "    metric to rank vendors.\n",
    "\n",
    "**Implementation Details:**\n",
    "This notebook orchestrates the following implementation steps:\n",
    " -   Loading of preprocessed Telegram data and the custom-trained NER model (from a Hugging Face repository or local path).\n",
    " -   Performing high-throughput NER inference across all available messages to enrich vendor profiles with extracted product and pricing information.\n",
    " -   Calculating vendor-specific metrics including:\n",
    "     -   **Posting Frequency:** Measuring the regularity and volume of a vendor's posts.\n",
    "     -   **Average Views per Post:** Quantifying the reach and engagement of a vendor's content.\n",
    "     -   **Average Price Point:** Analyzing the typical pricing of products offered, indicating market segment.\n",
    "     -   **Top Performing Post Analysis:** Identifying the most successful posts and their associated product-price pairs.\n",
    " -   Normalizing these metrics and applying predefined weights to compute the final \"Lending Score\".\n",
    " -   Presenting a comprehensive summary table of the calculated metrics and Lending Scores,\n",
    "     sorted for immediate business insights, along with detailed interpretations of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Setup and Library Installation ---\n",
    "# Install necessary libraries if running in a fresh Colab environment\n",
    "# !pip install pandas numpy transformers scikit-learn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "# Set up logging for informative messages\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import Hugging Face components for loading the fine-tuned model\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Paths and Configuration ---\n",
    "# Assuming the notebook is in 'notebooks/' and project root is its parent's parent\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "\n",
    "# Paths to data and model\n",
    "# Ensure preprocessed_telegram_data.csv has 'views', 'date', 'channel' columns\n",
    "# (These should ideally be passed through during preprocessing or original merged data used)\n",
    "PREPROCESSED_DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / 'preprocessed_telegram_data.csv'\n",
    "\n",
    "# --- IMPORTANT CHANGE: Load model from Hugging Face Hub ---\n",
    "# Replace \"YOUR_HF_USERNAME/your_ner_model_repo\" with your actual Hugging Face model repository name.\n",
    "# Example: \"your-username/xlm-roberta-base-finetuned-amharic-ner\"\n",
    "# Ensure the model was pushed to the hub in Task 4.\n",
    "FINE_TUNED_MODEL_NAME_OR_PATH = \"xlm-roberta-base\" # Default to local if not pushing to hub, or replace with your HF repo.\n",
    "                                                  # e.g., \"YOUR_HF_USERNAME/your_amharic_ner_model\"\n",
    "# For demonstration, we'll try to load locally first, then fallback to hub if specified.\n",
    "# If you pushed your model to HF Hub, replace 'xlm-roberta-base' with your repo name.\n",
    "# E.g., FINE_TUNED_MODEL_NAME_OR_PATH = \"your_hf_username/your_finetuned_model_repo\"\n",
    "# If running locally without pushing to HF Hub, keep this as the path to your saved model directory.\n",
    "if (PROJECT_ROOT / 'fine_tuned_ner_model').exists():\n",
    "    FINE_TUNED_MODEL_NAME_OR_PATH = str(PROJECT_ROOT / 'fine_tuned_ner_model')\n",
    "    logger.info(f\"Loading model from local path: {FINE_TUNED_MODEL_NAME_OR_PATH}\")\n",
    "else:\n",
    "    # If the local path doesn't exist, assume it's a Hugging Face Hub model name\n",
    "    # You MUST replace \"YOUR_HF_USERNAME/your_ner_model_repo\" with your actual model name on Hugging Face Hub\n",
    "    # This is a placeholder and will likely fail if you haven't uploaded it.\n",
    "    FINE_TUNED_MODEL_NAME_OR_PATH = \"xlm-roberta-base\" # Fallback to base model for demo if local not found\n",
    "    logger.warning(f\"Local fine-tuned model not found. Attempting to load '{FINE_TUNED_MODEL_NAME_OR_PATH}'. \"\n",
    "                   f\"Please ensure your model is uploaded to Hugging Face Hub or exists locally.\")\n",
    "\n",
    "\n",
    "# Output for the vendor scorecard\n",
    "VENDOR_SCORECARD_PATH = PROJECT_ROOT / 'data' / 'processed' / 'vendor_scorecard.csv'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Preprocessed data path: {PREPROCESSED_DATA_PATH}\")\n",
    "print(f\"Fine-tuned model loading from: {FINE_TUNED_MODEL_NAME_OR_PATH}\")\n",
    "print(f\"Vendor scorecard output path: {VENDOR_SCORECARD_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Load Data and Fine-tuned NER Model ---\n",
    "\n",
    "# Load preprocessed data (should ideally contain views, date, channel, and preprocessed_text)\n",
    "if not PREPROCESSED_DATA_PATH.exists():\n",
    "    logger.error(f\"Error: Preprocessed data not found at {PREPROCESSED_DATA_PATH}. Please ensure preprocessing output is available and includes metadata.\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data not found: {PREPROCESSED_DATA_PATH}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(PREPROCESSED_DATA_PATH)\n",
    "    logger.info(f\"Loaded {len(df)} rows from {PREPROCESSED_DATA_PATH}\")\n",
    "    # Basic check for essential columns for this analysis\n",
    "    required_cols = ['preprocessed_text', 'views', 'date', 'channel']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        logger.error(f\"Missing one or more required columns ({required_cols}) in the dataframe. This will prevent scorecard generation.\")\n",
    "        logger.error(\"Please ensure src/data_preprocessing/text_processor.py::preprocess_dataframe passes through 'views', 'date', and 'channel' columns from the raw data.\")\n",
    "        raise ValueError(\"Essential metadata (views, date, channel) columns are missing in the input DataFrame.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load or validate data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert 'date' column to datetime objects\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df.dropna(subset=['date', 'views', 'channel', 'preprocessed_text'], inplace=True)\n",
    "df['views'] = pd.to_numeric(df['views'], errors='coerce') # Ensure views is numeric\n",
    "logger.info(f\"DataFrame after dropping rows with missing essential metadata and coercing views: {len(df)} rows.\")\n",
    "\n",
    "# Load the fine-tuned NER model and tokenizer\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(FINE_TUNED_MODEL_NAME_OR_PATH)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(FINE_TUNED_MODEL_NAME_OR_PATH)\n",
    "    \n",
    "    # Create an NER pipeline for efficient inference\n",
    "    ner_pipeline = pipeline(\n",
    "        \"token-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        aggregation_strategy=\"simple\" # Aggregates sub-word tokens to full words\n",
    "    )\n",
    "    logger.info(\"Fine-tuned NER model and tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load fine-tuned model or create pipeline from '{FINE_TUNED_MODEL_NAME_OR_PATH}': {e}\")\n",
    "    logger.error(\"Please verify the model path/name and ensure it exists locally or on Hugging Face Hub.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Perform NER Inference on All Data ---\n",
    "logger.info(\"Starting NER inference on all preprocessed messages...\")\n",
    "\n",
    "# Apply NER to all preprocessed text\n",
    "# This might take a while depending on the number of messages and GPU availability\n",
    "ner_results = []\n",
    "for i, text in enumerate(df['preprocessed_text']):\n",
    "    if pd.isna(text) or not text.strip():\n",
    "        ner_results.append([]) # Append empty list for empty/NaN texts\n",
    "        continue\n",
    "    try:\n",
    "        results = ner_pipeline(text)\n",
    "        ner_results.append(results)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error during NER for message {i}: {e}. Appending empty result.\")\n",
    "        ner_results.append([])\n",
    "\n",
    "df['extracted_entities'] = ner_results\n",
    "logger.info(\"NER inference complete. Extracted entities column added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Entity Extraction and Normalization Helpers ---\n",
    "\n",
    "def extract_entities_by_type(entities: List[Dict], entity_type: str) -> List[str]:\n",
    "    \"\"\"Extracts all entities of a specific type from a list of NER results.\"\"\"\n",
    "    return [ent['word'] for ent in entities if ent['entity_group'] == entity_type]\n",
    "\n",
    "def extract_numerical_price(price_tokens: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Extracts and converts a price entity (e.g., ['5000', 'ብር']) into a float.\n",
    "    Handles commas, currency symbols, and ensures valid conversion.\n",
    "    \"\"\"\n",
    "    if not price_tokens:\n",
    "        return np.nan\n",
    "    \n",
    "    # Join tokens and convert to lowercase for robust matching\n",
    "    full_price_str = \"\".join(price_tokens).lower()\n",
    "    \n",
    "    # Remove common Amharic currency terms and symbols and symbols, as well as commas and spaces\n",
    "    # Add more variations as observed in data (e.g., 'ብር', ' birr', 'eth', 'etb', '$')\n",
    "    price_value_str = re.sub(r'[ብርbirr\\s,]', '', full_price_str)\n",
    "    \n",
    "    try:\n",
    "        return float(price_value_str)\n",
    "    except ValueError:\n",
    "        logger.warning(f\"Could not convert price '{full_price_str}' to float. Returning NaN.\")\n",
    "        return np.nan\n",
    "\n",
    "# Extract specific entity types into new columns\n",
    "df['products'] = df['extracted_entities'].apply(lambda x: extract_entities_by_type(x, 'PRODUCT'))\n",
    "df['prices'] = df['extracted_entities'].apply(lambda x: extract_entities_by_type(x, 'PRICE'))\n",
    "df['locations'] = df['extracted_entities'].apply(lambda x: extract_entities_by_type(x, 'LOC'))\n",
    "df['contact_info'] = df['extracted_entities'].apply(lambda x: extract_entities_by_type(x, 'CONTACT_INFO'))\n",
    "\n",
    "# Convert extracted price strings to numerical values\n",
    "# Note: For multiple prices in one message, this will create a list of numerical prices.\n",
    "df['numerical_prices'] = df['prices'].apply(lambda x: [extract_numerical_price([p]) for p in x if p])\n",
    "# Flatten the list of numerical prices for easier average calculation across all products in a message\n",
    "df['all_numerical_prices'] = df['numerical_prices'].apply(lambda x: [val for val in x if not pd.isna(val)])\n",
    "\n",
    "logger.info(\"Extracted specific entities and converted prices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Develop Vendor Analytics Engine & Calculate Key Metrics ---\n",
    "\n",
    "def calculate_vendor_metrics(df_vendor: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculates key performance metrics for a single vendor.\n",
    "\n",
    "    Args:\n",
    "        df_vendor (pd.DataFrame): DataFrame containing posts for a single vendor.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary of calculated metrics for the vendor.\n",
    "    \"\"\"\n",
    "    if df_vendor.empty:\n",
    "        return {\n",
    "            'Avg. Views/Post': 0,\n",
    "            'Posts/Week': 0,\n",
    "            'Avg. Price (ETB)': 0,\n",
    "            'Top Product': 'N/A',\n",
    "            'Top Product Price': 'N/A',\n",
    "            'Total Posts': 0,\n",
    "            'Date Range Days': 0\n",
    "        }\n",
    "\n",
    "    # Total Posts\n",
    "    total_posts = len(df_vendor)\n",
    "\n",
    "    # Average Views per Post\n",
    "    avg_views_per_post = df_vendor['views'].mean() if not df_vendor['views'].empty else 0\n",
    "\n",
    "    # Posting Frequency (Posts per Week)\n",
    "    min_date = df_vendor['date'].min()\n",
    "    max_date = df_vendor['date'].max()\n",
    "    date_range_days = (max_date - min_date).days + 1 # +1 to include both start and end day\n",
    "    \n",
    "    if date_range_days <= 0: # Handle cases where there's only one post or invalid date range\n",
    "        posting_frequency = total_posts # Consider all posts within a \"single period\"\n",
    "        date_range_days = 1 # Set to 1 to avoid division by zero later if used\n",
    "    else:\n",
    "        posting_frequency = total_posts / (date_range_days / 7) # Posts per 7 days\n",
    "\n",
    "    # Average Price Point\n",
    "    # Flatten all prices from all posts of the vendor\n",
    "    all_prices_flat = [price for sublist in df_vendor['all_numerical_prices'] for price in sublist]\n",
    "    avg_price_point = np.mean(all_prices_flat) if all_prices_flat else np.nan\n",
    "\n",
    "    # Top Performing Post - find the message with the highest view count\n",
    "    top_post = df_vendor.loc[df_vendor['views'].idxmax()]\n",
    "    # Get the first product if available, otherwise 'N/A'\n",
    "    top_product = top_post['products'][0] if top_post['products'] else 'N/A'\n",
    "    # Get the first numerical price if available, otherwise NaN\n",
    "    top_product_price = top_post['all_numerical_prices'][0] if top_post['all_numerical_prices'] else np.nan\n",
    "    \n",
    "    return {\n",
    "        'Total Posts': total_posts,\n",
    "        'Avg. Views/Post': avg_views_per_post,\n",
    "        'Posts/Week': posting_frequency,\n",
    "        'Avg. Price (ETB)': avg_price_point,\n",
    "        'Top Product': top_product,\n",
    "        'Top Product Price': top_product_price,\n",
    "        'Date Range Days': date_range_days # Useful for debugging frequency\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Process All Vendors ---\n",
    "logger.info(\"Calculating metrics for all unique vendors...\")\n",
    "vendor_metrics_list = []\n",
    "unique_vendors = df['channel'].unique()\n",
    "\n",
    "for vendor_name in unique_vendors:\n",
    "    df_vendor = df[df['channel'] == vendor_name].copy()\n",
    "    metrics = calculate_vendor_metrics(df_vendor)\n",
    "    metrics['Vendor'] = vendor_name\n",
    "    vendor_metrics_list.append(metrics)\n",
    "\n",
    "vendor_scorecard_df = pd.DataFrame(vendor_metrics_list)\n",
    "\n",
    "logger.info(\"Vendor metrics calculated.\")\n",
    "print(\"\\nRaw Vendor Metrics:\")\n",
    "print(vendor_scorecard_df[['Vendor', 'Total Posts', 'Avg. Views/Post', 'Posts/Week', 'Avg. Price (ETB)', 'Top Product', 'Top Product Price']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Key Vendor Metrics\n",
    "**Average Views per Post:**\n",
    "This metric directly reflects a vendor's market reach and the level of customer engagement their content generates. A higher average view count indicates that the vendor's posts are being seen by more potential customers, suggesting broader visibility and potentially more interest in their products.\n",
    "\n",
    "**Posting Frequency (Posts per Week):**\n",
    "This metric indicates a vendor's activity and consistency. A higher posting frequency suggests an active and potentially reliable business that regularly engages its audience and updates its product offerings. Consistent activity is a positive signal for potential micro-lending.\n",
    "\n",
    "**Average Price Point (ETB):**\n",
    "This metric provides insight into a vendor's business profile and market segment. A higher average price point might indicate a vendor dealing in higher-value, lower-volume products (e.g., electronics, specialized machinery), while a lower average price point could suggest a high-volume, lower-margin business (e.g., common household goods, fast-moving consumer goods). This helps lenders understand the scale and nature of the business.\n",
    "\n",
    "**Top Performing Post (Product & Price):**\n",
    "Identifying the product and its price from the highest-viewed post helps understand what kind of content or product resonates most with a vendor's audience. This provides qualitative insight into their most successful offerings, which can be valuable for business assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Create a Final \"Lending Score\" ---\n",
    "# Normalize metrics before combining them to ensure fair weighting\n",
    "# We will use Min-Max scaling: (X - min(X)) / (max(X) - min(X))\n",
    "\n",
    "# Define metrics to normalize and their importance (weights)\n",
    "# Example weights, these can be adjusted based on business priorities\n",
    "# Views and Posting Frequency are often good indicators of engagement.\n",
    "# Price point might indicate market segment (luxury vs. mass market).\n",
    "METRIC_WEIGHTS = {\n",
    "    'Avg. Views/Post': 0.4,\n",
    "    'Posts/Week': 0.4,\n",
    "    'Avg. Price (ETB)': 0.2, # Lower weight as it defines market segment, not directly engagement\n",
    "}\n",
    "\n",
    "# Ensure columns exist and handle NaNs for normalization\n",
    "for col in METRIC_WEIGHTS.keys():\n",
    "    if col not in vendor_scorecard_df.columns:\n",
    "        vendor_scorecard_df[col] = 0.0 # Add column with zeros if missing\n",
    "    # Replace NaNs with 0 for metrics where it makes sense (e.g., if no prices were extracted)\n",
    "    vendor_scorecard_df[col] = vendor_scorecard_df[col].fillna(0)\n",
    "\n",
    "# Normalize relevant columns\n",
    "normalized_df = vendor_scorecard_df.copy()\n",
    "for metric, weight in METRIC_WEIGHTS.items():\n",
    "    min_val = normalized_df[metric].min()\n",
    "    max_val = normalized_df[metric].max()\n",
    "    \n",
    "    if max_val == min_val: # Avoid division by zero if all values are the same\n",
    "        normalized_df[f'Normalized {metric}'] = 0.0\n",
    "    else:\n",
    "        normalized_df[f'Normalized {metric}'] = (normalized_df[metric] - min_val) / (max_val - min_val)\n",
    "        \n",
    "    logger.info(f\"Normalized '{metric}' (Min: {min_val:.2f}, Max: {max_val:.2f})\")\n",
    "\n",
    "# Calculate the Lending Score\n",
    "normalized_df['Lending Score'] = 0.0\n",
    "for metric, weight in METRIC_WEIGHTS.items():\n",
    "    normalized_df['Lending Score'] += normalized_df[f'Normalized {metric}'] * weight\n",
    "\n",
    "# Optionally scale Lending Score to 0-100 or another range for easier interpretation\n",
    "max_possible_score = sum(METRIC_WEIGHTS.values()) # Should be 1.0 if weights sum to 1\n",
    "normalized_df['Lending Score (0-100)'] = (normalized_df['Lending Score'] / max_possible_score) * 100\n",
    "\n",
    "logger.info(\"Lending Score calculated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Lending Score\n",
    "The 'Lending Score' is a composite metric designed to identify promising vendors for micro-lending. It is calculated as a weighted sum of normalized key performance indicators:\n",
    "  - Average Views per Post (Weight: 0.4): Reflects market reach and customer engagement.\n",
    "  - Posting Frequency (Weight: 0.4): Indicates business activity and consistency.\n",
    "  - Average Price Point (Weight: 0.2): Provides insight into the vendor's market segment (e.g., high-value vs. high-volume goods).\n",
    "\n",
    "A higher Lending Score (on a scale of 0-100) suggests a vendor with stronger engagement, consistent activity, and a potentially viable business model based on their Telegram presence. This score serves as a data-driven input for EthioMart's micro-lending decisions, complementing traditional financial assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Present Vendor Scorecard Table ---\n",
    "final_scorecard_display = normalized_df[[\n",
    "    'Vendor',\n",
    "    'Avg. Views/Post',\n",
    "    'Posts/Week',\n",
    "    'Avg. Price (ETB)',\n",
    "    'Top Product',\n",
    "    'Top Product Price',\n",
    "    'Lending Score (0-100)'\n",
    "]].sort_values(by='Lending Score (0-100)', ascending=False) # Sort by lending score\n",
    "\n",
    "print(\"\\n--- FinTech Vendor Scorecard Summary ---\")\n",
    "print(\"The table below presents the calculated metrics and the composite 'Lending Score' for each analyzed vendor. Vendors are sorted by their Lending Score in descending order, with higher scores indicating potentially more promising candidates for micro-lending.\")\n",
    "print(final_scorecard_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Result Summary ---\n",
    "if not final_scorecard_display.empty:\n",
    "    top_vendor = final_scorecard_display.iloc[0]\n",
    "    print(\"\\n**Top Performing Vendor:**\")\n",
    "    print(f\"  - Vendor: {top_vendor['Vendor']}\")\n",
    "    print(f\"  - Lending Score (0-100): {top_vendor['Lending Score (0-100)']:.2f}\")\n",
    "    print(f\"  - Avg. Views/Post: {top_vendor['Avg. Views/Post']:.2f}\")\n",
    "    print(f\"  - Posts/Week: {top_vendor['Posts/Week']:.2f}\")\n",
    "    print(f\"  - Average Price (ETB): {top_vendor['Avg. Price (ETB)'] if not pd.isna(top_vendor['Avg. Price (ETB)']) else 'N/A'}\")\n",
    "    print(f\"  - Top Product: {top_vendor['Top Product']}\")\n",
    "    print(f\"  - Top Product Price: {top_vendor['Top Product Price'] if not pd.isna(top_vendor['Top Product Price']) else 'N/A'}\")\n",
    "    print(\"\\nThis vendor demonstrates strong online activity and customer engagement, making them a prime candidate for micro-lending based on their Telegram presence.\")\n",
    "    \n",
    "    if len(final_scorecard_display) > 1:\n",
    "        bottom_vendor = final_scorecard_display.iloc[-1]\n",
    "        print(\"\\n**Lowest Performing Vendor (for comparison):**\")\n",
    "        print(f\"  - Vendor: {bottom_vendor['Vendor']}\")\n",
    "        print(f\"  - Lending Score (0-100): {bottom_vendor['Lending Score (0-100)']:.2f}\")\n",
    "        print(f\"  - Avg. Views/Post: {bottom_vendor['Avg. Views/Post']:.2f}\")\n",
    "        print(f\"  - Posts/Week: {bottom_vendor['Posts/Week']:.2f}\")\n",
    "        print(f\"  - Average Price (ETB): {bottom_vendor['Avg. Price (ETB)'] if not pd.isna(bottom_vendor['Avg. Price (ETB)']) else 'N/A'}\")\n",
    "        print(f\"  - Top Product: {bottom_vendor['Top Product']}\")\n",
    "        print(f\"  - Top Product Price: {bottom_vendor['Top Product Price'] if not pd.isna(bottom_vendor['Top Product Price']) else 'N/A'}\")\n",
    "        print(\"\\nThis vendor shows lower activity and engagement, indicating a less promising profile for micro-lending based solely on Telegram data.\")\n",
    "else:\n",
    "    print(\"No vendor data available to generate a summary.\")\n",
    "\n",
    "# --- 10. Save the Scorecard ---\n",
    "os.makedirs(VENDOR_SCORECARD_PATH.parent, exist_ok=True)\n",
    "final_scorecard_display.to_csv(VENDOR_SCORECARD_PATH, index=False, encoding='utf-8')\n",
    "logger.info(f\"\\nVendor scorecard saved to: {VENDOR_SCORECARD_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
